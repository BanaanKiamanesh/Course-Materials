{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **0. Download Dataset**\n",
        "\n",
        "[dataset : doi:10.18150/repod.0107441](https://repod.icm.edu.pl/dataset.xhtml?persistentId=doi:10.18150/repod.0107441)"
      ],
      "metadata": {
        "id": "97DRuy7v1lMF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKwpJBuw1Zaj",
        "outputId": "5f8f2667-26a9-4ae5-be9f-b00a188fdd8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "  inflating: h01.edf                 \n",
            "  inflating: h02.edf                 \n",
            "  inflating: h03.edf                 \n",
            "  inflating: h04.edf                 \n",
            "  inflating: h05.edf                 \n",
            "  inflating: h06.edf                 \n",
            "  inflating: h07.edf                 \n",
            "  inflating: h08.edf                 \n",
            "  inflating: h09.edf                 \n",
            "  inflating: h10.edf                 \n",
            "  inflating: h11.edf                 \n",
            "  inflating: h12.edf                 \n",
            "  inflating: h13.edf                 \n",
            "  inflating: h14.edf                 \n",
            "  inflating: s01.edf                 \n",
            "  inflating: s02.edf                 \n",
            "  inflating: s03.edf                 \n",
            "  inflating: s04.edf                 \n",
            "  inflating: s05.edf                 \n",
            "  inflating: s06.edf                 \n",
            "  inflating: s07.edf                 \n",
            "  inflating: s08.edf                 \n",
            "  inflating: s09.edf                 \n",
            "  inflating: s10.edf                 \n",
            "  inflating: s11.edf                 \n",
            "  inflating: s12.edf                 \n",
            "  inflating: s13.edf                 \n",
            "  inflating: s14.edf                 \n",
            "  inflating: MANIFEST.TXT            \n"
          ]
        }
      ],
      "source": [
        "!wget -q https://repod.icm.edu.pl/api/datasets/251/versions/59/files/download?format=original -O data.zip\n",
        "!unzip data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Download and Install Dependencies**"
      ],
      "metadata": {
        "id": "_KQ63PiD_Sxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from scipy import stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wtCiBXz_SEF",
        "outputId": "718bad50-79fc-4124-b3ca-041bd7eee088"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.7.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.1)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.2.2)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Load and Preprocess Data**"
      ],
      "metadata": {
        "id": "uqjxwNRt_02z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Data\n",
        "h_path = glob(\"./h*.edf\")      # Healthy\n",
        "s_path = glob(\"./s*.edf\")      # Schizophernic\n",
        "\n",
        "len(h_path), len(s_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ1vcElMAHTG",
        "outputId": "ae08e680-c7c0-402a-b7ed-d2ea6a12d384"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(path):\n",
        "    '''\n",
        "        Funtion to Read Data from Path and Apply Simple Preprocessing\n",
        "\n",
        "        inputs:\n",
        "            path ==> path to the data\n",
        "\n",
        "        outputs:\n",
        "            output ==> epoch/trial array\n",
        "    '''\n",
        "\n",
        "    data = mne.io.read_raw(path, preload=True, verbose=False)               # Read Data\n",
        "    data = data.set_eeg_reference('average', verbose=False)                 # Apply Referencing\n",
        "    data = data.filter(l_freq=0.1, h_freq=50, n_jobs=-1, verbose=False)     # Filter Data\n",
        "\n",
        "    # Seperate Epochs\n",
        "    epoch = mne.make_fixed_length_epochs(data, duration=5, overlap=1, verbose=False)\n",
        "\n",
        "    return epoch.get_data(verbose=False)"
      ],
      "metadata": {
        "id": "OVlLM57RAHVl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Apply on Data to Create Train Data\n",
        "h_data = np.vstack([read_data(path) for path in h_path])\n",
        "s_data = np.vstack([read_data(path) for path in s_path])\n",
        "\n",
        "# Check Data Shapes\n",
        "h_data.shape, s_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB4CL9C8AHZ1",
        "outputId": "6f26f1fb-2677-4410-f628-ec27b2736dcc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3251, 19, 1250), (3950, 19, 1250))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Labels for Data\n",
        "h_label = np.zeros(len(h_data))\n",
        "s_label = np.ones(len(s_data))\n",
        "\n",
        "# Check Data Shapes\n",
        "h_label.shape, s_label.shape"
      ],
      "metadata": {
        "id": "X8OyJQy1G3BM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39879014-3dfc-4538-f7a0-b488e92ab544"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3251,), (3950,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Merge Data\n",
        "X = np.vstack((h_data, s_data))\n",
        "Y = np.concatenate((h_label, s_label))\n",
        "\n",
        "# Check Data Shapes\n",
        "X.shape, Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFpY42q5Hadi",
        "outputId": "49632684-e46c-4fdd-f3b9-3f220d46419e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7201, 19, 1250), (7201,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.1 PreProcessing**"
      ],
      "metadata": {
        "id": "invlDo3LKIHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.fft import fft\n",
        "\n",
        "def get_features(data):\n",
        "    \"\"\"\n",
        "    Calculate various statistical features from the given EEG data.\n",
        "\n",
        "    Inputes:\n",
        "        data (ndarray) ==> Input data array.\n",
        "\n",
        "    Outputs:\n",
        "        ndarray ==> Concatenated array of statistical features.\n",
        "    \"\"\"\n",
        "\n",
        "    features = [\n",
        "        np.mean(data, axis=-1),                           # Mean\n",
        "        np.std(data, axis=-1),                            # Standard Deviation\n",
        "        np.ptp(data, axis=-1),                            # Peak-to-Peak (Range)\n",
        "        np.var(data, axis=-1),                            # Variance\n",
        "        np.min(data, axis=-1),                            # Minimum\n",
        "        np.max(data, axis=-1),                            # Maximum\n",
        "        np.argmin(data, axis=-1),                         # Index of Minimum\n",
        "        np.argmax(data, axis=-1),                         # Index of Maximum\n",
        "        np.mean(data**2, axis=-1),                        # Mean Square\n",
        "        np.sqrt(np.mean(data**2, axis=-1)),               # Root Mean Square (RMS)\n",
        "        np.sum(np.abs(np.diff(data, axis=-1)), axis=-1),  # Absolute Differences Sum\n",
        "        stats.skew(data, axis=-1),                        # Skewness\n",
        "        stats.kurtosis(data, axis=-1)                     # Kurtosis\n",
        "    ]\n",
        "\n",
        "    return np.concatenate(features, axis=-1)\n",
        "\n",
        "def feature_extractor(data):\n",
        "    \"\"\"\n",
        "    Extract comprehensive time domain and frequency domain features from EEG data.\n",
        "\n",
        "    Inputes:\n",
        "        data : ndarray\n",
        "            Input EEG data in the shape (channels, samples).\n",
        "    Outputs:\n",
        "        ndarray  :\n",
        "            Concatenated array of time domain and frequency domain features extracted from the input data.\n",
        "            Features include statistical descriptors computed across each channel in both domains.\n",
        "    \"\"\"\n",
        "\n",
        "    # Time Domain Features\n",
        "    time_domain_features = get_features(data)\n",
        "\n",
        "    # Frequency Domain Features\n",
        "    fft_data = np.abs(fft(data))[:, :data.shape[1] // 2]  # Compute FFT and take positive frequencies\n",
        "    frequency_domain_features = get_features(fft_data)\n",
        "\n",
        "    # Concatenate time domain and frequency domain features\n",
        "    all_features = [\n",
        "        *time_domain_features,\n",
        "        *frequency_domain_features\n",
        "    ]\n",
        "\n",
        "    return np.array(all_features)"
      ],
      "metadata": {
        "id": "Sh9OIVeDKLO7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction\n",
        "x = np.vstack([feature_extractor(X[i, :, :]) for i in range(len(X))])\n",
        "\n",
        "# Check Feature Data Shape\n",
        "x.shape"
      ],
      "metadata": {
        "id": "0HtCTtq4KUZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef765df1-acaf-4042-c0e6-bb00fbd2e6c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7201, 494)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Classification**"
      ],
      "metadata": {
        "id": "w3choV5AyKhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "IGJcdsmoKLRX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and test sets\n",
        "x_train, x_test, Y_train, Y_test = train_test_split(x, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a pipeline with StandardScaler, PCA, and KNN classifier\n",
        "Pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components=28)),\n",
        "    ('clf', KNeighborsClassifier(n_neighbors=13))\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "Pipe.fit(x_train, Y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "Y_pred = Pipe.predict(x_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX2CZpDzKLVt",
        "outputId": "3a148f91-af67-4f94-a0df-8984f3e0ba3a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8056904927133934\n"
          ]
        }
      ]
    }
  ]
}